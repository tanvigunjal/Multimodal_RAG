# Multimodal RAG Project

This project is a sophisticated, production-ready Retrieval-Augmented Generation (RAG) application designed to answer queries based on a diverse range of documents. It leverages a powerful multimodal ingestion pipeline, a robust vector database, and state-of-the-art language models to provide accurate, context-aware responses.

## âœ¨ Features

- **Multimodal Data Ingestion:** Supports a wide variety of file formats, including PDF, images, and more, by leveraging the `unstructured` library.
- **Advanced RAG Pipeline:** Utilizes LangChain for orchestrating a complex RAG pipeline, including document chunking, embedding, and retrieval.
- **State-of-the-Art LLMs:** Integrates with Google's Generative AI models to provide high-quality, conversational answers.
- **High-Performance Vector Store:** Uses Qdrant as a scalable and efficient vector database for storing and retrieving document embeddings.
- **Web-Based UI:** A clean and intuitive frontend built with HTML, CSS, and JavaScript for easy interaction with the RAG agent.
- **Containerized Deployment:** Fully containerized with Docker and Docker Compose for easy setup, portability, and scalability.
- **Production-Ready:** Includes health checks, environment-based configuration, and a scalable architecture.

## ğŸ—ï¸ Architecture Overview

The application is composed of three main services orchestrated by Docker Compose:

1.  **Frontend:** A static web interface served by Nginx that allows users to:
    - Upload and manage documents
    - Interactive chat interface
    - Real-time document processing status
    - Theme customization
    - User authentication

2.  **Backend:** A FastAPI application that provides:
    - REST API for document ingestion and querying
    - Core RAG logic implementation
    - Document processing and embedding generation
    - Authentication and session management
    - Health monitoring endpoints
    - Language model integration
    - Vectorization services

3.  **Qdrant:** Vector database service that provides:
    - Efficient vector storage and retrieval
    - Similarity search capabilities
    - Persistent storage
    - High-performance querying
    - Scalable architecture


### System Components

#### Ingestion Pipeline
- Document extraction and parsing using advanced adapters
- Smart chunking with configurable strategies
- Content enrichment and metadata extraction
- Vector embedding generation
- Efficient storage management

#### RAG System
- Context-aware retrieval based on queries
- Advanced prompt engineering
- Tool-augmented generation
- Response quality optimization

#### Security
- User authentication
- Session management
- Secure file handling
- Access control

## ğŸš€ Getting Started

Follow these instructions to get the project up and running on your local machine.

### Prerequisites

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)
- A Google Generative AI API key

### Installation & Configuration

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd <repository-name>
    ```

2.  **Create an environment file:**
    Copy the example environment file and fill in the required values.
    ```bash
    cp .env.example .env
    ```
    You will need to add your `GOOGLE_API_KEY` to this file.

3.  **Build and run the application:**
    Use Docker Compose to build the images and start the services in detached mode.
    ```bash
    docker compose up --build -d
    ```

### Usage

1.  **Access the web interface:**
    Open your web browser and navigate to `http://localhost:8081`.

2.  **Upload documents:**
    Use the UI to upload the documents you want to query. The backend will process and ingest them into the vector database.

3.  **Ask questions:**
    Once the documents are ingested, you can start asking questions through the chat interface. The RAG agent will retrieve relevant information from the documents and generate a comprehensive answer.

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ data/                   # Directory for uploaded and processed documents
â”‚   â””â”€â”€ uploads/           # Storage for user uploads
â”œâ”€â”€ docker-compose.yml      # Docker Compose configuration
â”œâ”€â”€ Dockerfile             # Dockerfile for the backend service
â”œâ”€â”€ frontend/              # Frontend source code
â”‚   â”œâ”€â”€ index.html        # Main application page
â”‚   â”œâ”€â”€ login.html        # Authentication page
â”‚   â”œâ”€â”€ style.css         # Global styles
â”‚   â””â”€â”€ js/               # JavaScript modules
â”‚       â”œâ”€â”€ api.js        # API integration
â”‚       â”œâ”€â”€ chat.js       # Chat functionality
â”‚       â”œâ”€â”€ uploads.js    # File upload handling
â”‚       â””â”€â”€ ...          # Other modules
â”œâ”€â”€ nginx.conf            # Nginx configuration for the frontend
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ src/                 # Backend source code (FastAPI)
    â”œâ”€â”€ api/             # API endpoints and main application
    â”‚   â”œâ”€â”€ app.py      # FastAPI application
    â”‚   â”œâ”€â”€ auth.py     # Authentication logic
    â”‚   â””â”€â”€ endpoints.py # API routes
    â”œâ”€â”€ core/            # Core RAG logic
    â”‚   â”œâ”€â”€ agent.py    # RAG agent implementation
    â”‚   â”œâ”€â”€ prompt.py   # Prompt engineering
    â”‚   â””â”€â”€ tools.py    # Agent tools
    â”œâ”€â”€ ingestion/       # Document processing pipeline
    â”‚   â”œâ”€â”€ adapter.py  # File format adapters
    â”‚   â”œâ”€â”€ chunker.py  # Text chunking
    â”‚   â””â”€â”€ enricher.py # Content enrichment
    â”œâ”€â”€ services/        # External service integrations
    â”‚   â”œâ”€â”€ embedding_service.py # Vector embeddings
    â”‚   â”œâ”€â”€ llm_service.py      # LLM integration
    â”‚   â””â”€â”€ vectordb_service.py # Qdrant client
    â””â”€â”€ utils/           # Utility functions
        â””â”€â”€ logger.py    # Logging configuration
```

### Troubleshooting

Common issues and solutions:

1. **Backend Service Issues:**
   - Check logs: `docker compose logs backend`
   - Verify environment variables
   - Ensure Google API key is valid

2. **Vector Database Issues:**
   - Check Qdrant status: `curl http://localhost:6333/health`
   - Verify storage permissions
   - Check available disk space

3. **Frontend Issues:**
   - Clear browser cache
   - Check browser console for errors
   - Verify nginx configuration

